# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Text-to-Video Generator

## üèõÔ∏è –û–±—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### –ü—Ä–∏–Ω—Ü–∏–ø—ã –¥–∏–∑–∞–π–Ω–∞

1. **–ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å** - –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º –∏ –≤–∑–∞–∏–º–æ–∑–∞–º–µ–Ω—è–µ–º
2. **–†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å** - –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ TTS –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã, —Ñ–æ—Ä–º–∞—Ç—ã, —Å—Ç–∏–ª–∏
3. **–û—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ —Å fallback
4. **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å** - –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ
5. **–ü—Ä–æ—Å—Ç–æ—Ç–∞** - –º–∏–Ω–∏–º—É–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, —á–∏—Å—Ç—ã–π –∫–æ–¥

---

## üì¶ –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥—É–ª–µ–π

### 1. `main.py` - –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**
- –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
- –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
- –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è

**–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–ª–æ—É:**
```python
def main():
    # 1. –ü–∞—Ä—Å–∏–Ω–≥ CLI –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
    args = parse_arguments()
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = load_config(args.config)
    
    # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–≥–µ—Ä–∞
    logger = setup_logger(config)
    
    # 4. –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    validate_input(args.input, config)
    
    # 5. –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
    pipeline = Pipeline(config)
    video_path = pipeline.run(args.input, args.output)
    
    # 6. –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
    logger.info(f"‚úÖ –í–∏–¥–µ–æ —Å–æ–∑–¥–∞–Ω–æ: {video_path}")
```

---

### 2. `modules/scene_parser.py` - –ü–∞—Ä—Å–µ—Ä —Å—Ü–µ–Ω

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**
- –ß—Ç–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ (.txt, .md)
- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Å—Ü–µ–Ω—ã –ø–æ –∞–±–∑–∞—Ü–∞–º
- –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
- –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**
```python
class SceneParser:
    def parse(self, file_path: str) -> List[Scene]:
        """–ü–∞—Ä—Å–∏—Ç —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ü–µ–Ω"""
        
    def split_into_scenes(self, text: str) -> List[str]:
        """–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ü–µ–Ω—ã"""
        
    def clean_text(self, text: str) -> str:
        """–£–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã"""
        
    def extract_metadata(self, text: str) -> dict:
        """–ò—â–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"""
```

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ Scene:**
```python
@dataclass
class Scene:
    id: int
    text: str
    duration: float = 0.0
    image_path: str = None
    audio_path: str = None
    metadata: dict = field(default_factory=dict)
```

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –ø—É—Å—Ç—ã–µ –∞–±–∑–∞—Ü—ã
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–∞—Ä–∫–¥–∞—É–Ω —Ä–∞–∑–º–µ—Ç–∫–∏ (–∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
- –û–±—Ä–∞–±–æ—Ç–∫–∞ Unicode –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É —Å—Ü–µ–Ω—ã (–¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ)

---

### 3. `modules/tts_generator.py` - –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ä–µ—á–∏

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**
- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Coqui TTS
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ WAV —Ñ–∞–π–ª–æ–≤
- –†–∞—Å—á–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**
```python
class TTSGenerator:
    def __init__(self, config: dict):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å TTS"""
        self.tts = TTS(model_name=config['tts']['model'])
        
    def generate(self, scene: Scene, output_dir: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –¥–ª—è —Å—Ü–µ–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É"""
        
    def get_audio_duration(self, audio_path: str) -> float:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        
    def batch_generate(self, scenes: List[Scene]) -> None:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å—Ü–µ–Ω"""
```

**–í–∞–∂–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã:**

1. **–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ:**
```python
# –•–µ—à —Ç–µ–∫—Å—Ç–∞ + –∫–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–∏ = —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
cache_key = hashlib.md5(f"{text}_{model}_{speed}".encode()).hexdigest()
if cache_key in cache:
    return cache[cache_key]
```

2. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫:**
- Fallback –Ω–∞ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –ø—Ä–∏ OOM
- –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —á–∞—Å—Ç–∏
- Retry –º–µ—Ö–∞–Ω–∏–∑–º –ø—Ä–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–±–æ—è—Ö

3. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**
- Lazy –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
- Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω

---

### 4. `modules/subtitle_generator.py` - –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å—É–±—Ç–∏—Ç—Ä–æ–≤

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**
- –°–æ–∑–¥–∞–Ω–∏–µ SRT —Ñ–∞–π–ª–æ–≤
- –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å –∞—É–¥–∏–æ
- –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –ø–æ –¥–ª–∏–Ω–µ
- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∏–ª–µ–π

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**
```python
class SubtitleGenerator:
    def generate(self, scene: Scene) -> str:
        """–°–æ–∑–¥–∞–µ—Ç SRT —Ñ–∞–π–ª –¥–ª—è —Å—Ü–µ–Ω—ã"""
        
    def split_into_lines(self, text: str, max_chars: int) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Å—É–±—Ç–∏—Ç—Ä–æ–≤"""
        
    def calculate_timings(self, text: str, audio_duration: float) -> List[Tuple]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–∞–π–º–∏–Ω–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏"""
        
    def apply_style(self, srt_path: str, style: dict) -> str:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å—Ç–∏–ª—å –∫ —Å—É–±—Ç–∏—Ç—Ä–∞–º (–¥–ª—è ASS —Ñ–æ—Ä–º–∞—Ç–∞)"""
```

**–ê–ª–≥–æ—Ä–∏—Ç–º —Ä–∞—Å—á–µ—Ç–∞ —Ç–∞–π–º–∏–Ω–≥–æ–≤:**
```python
def calculate_timings(text: str, duration: float):
    words = text.split()
    time_per_word = duration / len(words)
    
    lines = split_into_lines(text, max_chars=40)
    timings = []
    
    current_time = 0.0
    for line in lines:
        word_count = len(line.split())
        line_duration = word_count * time_per_word
        
        start = current_time
        end = current_time + line_duration
        timings.append((start, end, line))
        
        current_time = end
    
    return timings
```

**–§–æ—Ä–º–∞—Ç SRT:**
```
1
00:00:00,000 --> 00:00:03,500
–ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å—É–±—Ç–∏—Ç—Ä–æ–≤

2
00:00:03,500 --> 00:00:07,000
–í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ —Å—É–±—Ç–∏—Ç—Ä–æ–≤
```

---

### 5. `modules/visual_selector.py` - –°–µ–ª–µ–∫—Ç–æ—Ä –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ —Ä—è–¥–∞

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**
- –í—ã–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Å—Ü–µ–Ω
- –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥ —Ñ–æ—Ä–º–∞—Ç –≤–∏–¥–µ–æ
- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**
```python
class VisualSelector:
    def select_image(self, scene: Scene, images_dir: str) -> str:
        """–í—ã–±–∏—Ä–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Å—Ü–µ–Ω—ã"""
        
    def scale_image(self, image_path: str, target_resolution: tuple) -> str:
        """–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –≤–∏–¥–µ–æ"""
        
    def apply_ken_burns(self, image_path: str, duration: float) -> str:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç –ö–µ–Ω–∞ –ë—ë—Ä–Ω—Å–∞ (zoom/pan) - –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ"""
```

**–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤—ã–±–æ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:**

1. **–†–∞–Ω–¥–æ–º–Ω—ã–π –≤—ã–±–æ—Ä** (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é):
```python
images = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png'))]
return random.choice(images)
```

2. **–ü–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º** (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):
```python
keywords = extract_keywords(scene.text)
matching_images = find_images_by_keywords(images_dir, keywords)
return matching_images[0] if matching_images else fallback_image
```

3. **–ü–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º** (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ):
```python
# [image: sunset.jpg]
if 'image' in scene.metadata:
    return scene.metadata['image']
```

**–ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ:**
- Crop to fit (–æ–±—Ä–µ–∑–∫–∞ –ø–æ —Ü–µ–Ω—Ç—Ä—É)
- Letterbox (—á–µ—Ä–Ω—ã–µ –ø–æ–ª–æ—Å—ã)
- Stretch (—Ä–∞—Å—Ç—è–∂–µ–Ω–∏–µ)

---

### 6. `modules/music_selector.py` - –°–µ–ª–µ–∫—Ç–æ—Ä –º—É–∑—ã–∫–∏

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**
- –í—ã–±–æ—Ä —Ñ–æ–Ω–æ–≤–æ–π –º—É–∑—ã–∫–∏
- –ü–æ–¥—Ä–µ–∑–∫–∞/–∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ –ø–æ–¥ –¥–ª–∏–Ω—É –≤–∏–¥–µ–æ
- –ú–∏–∫—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ä–µ—á—å—é
- Fade in/out —ç—Ñ—Ñ–µ–∫—Ç—ã

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**
```python
class MusicSelector:
    def select_music(self, total_duration: float, mood: str = None) -> str:
        """–í—ã–±–∏—Ä–∞–µ—Ç –º—É–∑—ã–∫–∞–ª—å–Ω—ã–π —Ç—Ä–µ–∫"""
        
    def adjust_duration(self, music_path: str, target_duration: float) -> str:
        """–ü–æ–¥—Ä–µ–∑–∞–µ—Ç –∏–ª–∏ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ—Ç –º—É–∑—ã–∫—É"""
        
    def mix_with_voice(self, music_path: str, voice_path: str, 
                       music_volume: float) -> str:
        """–ú–∏–∫—à–∏—Ä—É–µ—Ç –º—É–∑—ã–∫—É —Å –≥–æ–ª–æ—Å–æ–º"""
```

**–ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**
```python
def detect_mood(text: str) -> str:
    """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–æ–Ω–∞"""
    positive_words = ['—Ä–∞–¥–æ—Å—Ç—å', '—Å—á–∞—Å—Ç—å–µ', '—É—Å–ø–µ—Ö']
    negative_words = ['–≥—Ä—É—Å—Ç—å', '–ø—Ä–æ–±–ª–µ–º–∞', '–±–µ–¥–∞']
    
    pos_count = sum(word in text.lower() for word in positive_words)
    neg_count = sum(word in text.lower() for word in negative_words)
    
    if pos_count > neg_count:
        return 'uplifting'
    elif neg_count > pos_count:
        return 'melancholic'
    else:
        return 'neutral'
```

---

### 7. `modules/video_assembler.py` - –°–±–æ—Ä—â–∏–∫ –≤–∏–¥–µ–æ

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å:**
- –ö–æ–º–ø–æ–∑–∏—Ç–∏–Ω–≥ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —Å—Ü–µ–Ω–∞–º–∏
- –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è

**–ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã:**
```python
class VideoAssembler:
    def assemble(self, scenes: List[Scene], config: dict) -> str:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ"""
        
    def create_scene_clip(self, scene: Scene) -> VideoClip:
        """–°–æ–∑–¥–∞–µ—Ç –∫–ª–∏–ø –¥–ª—è –æ–¥–Ω–æ–π —Å—Ü–µ–Ω—ã"""
        
    def apply_transition(self, clip1: VideoClip, clip2: VideoClip) -> VideoClip:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥ –º–µ–∂–¥—É –∫–ª–∏–ø–∞–º–∏"""
        
    def add_background_music(self, video: VideoClip, music_path: str) -> VideoClip:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –º—É–∑—ã–∫—É"""
```

**–ü–∞–π–ø–ª–∞–π–Ω —Å–±–æ—Ä–∫–∏:**
```python
def assemble(scenes, config):
    clips = []
    
    # 1. –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–ø–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã
    for scene in scenes:
        # –§–æ–Ω (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
        bg = ImageClip(scene.image_path).set_duration(scene.duration)
        
        # –ê—É–¥–∏–æ (–æ–∑–≤—É—á–∫–∞)
        audio = AudioFileClip(scene.audio_path)
        
        # –°—É–±—Ç–∏—Ç—Ä—ã
        subtitles = SubtitlesClip(scene.subtitle_path, 
                                   generator=lambda txt: TextClip(txt, ...))
        
        # –ö–æ–º–ø–æ–∑–∏—Ü–∏—è
        clip = CompositeVideoClip([bg, subtitles.set_position(('center', 'bottom'))])
        clip = clip.set_audio(audio)
        
        clips.append(clip)
    
    # 2. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
    clips_with_transitions = []
    for i in range(len(clips) - 1):
        clips_with_transitions.append(clips[i])
        transition = crossfadein(clips[i+1], duration=0.5)
        clips_with_transitions.append(transition)
    
    # 3. –ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è
    final = concatenate_videoclips(clips_with_transitions)
    
    # 4. –§–æ–Ω–æ–≤–∞—è –º—É–∑—ã–∫–∞
    if config['audio']['music']['enabled']:
        music = AudioFileClip(music_path).volumex(0.2)
        final_audio = CompositeAudioClip([final.audio, music])
        final = final.set_audio(final_audio)
    
    # 5. –†–µ–Ω–¥–µ—Ä–∏–Ω–≥
    final.write_videofile(output_path, 
                          fps=config['video']['fps'],
                          codec=config['video']['codec'])
    
    return output_path
```

---

## üîÑ –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É

```
1. INPUT: script.txt
   ‚îî‚îÄ> SceneParser
       ‚îî‚îÄ> [Scene 1, Scene 2, Scene 3]

2. TTSGenerator
   Scene 1 ‚Üí audio_scene1.wav (duration: 5.2s)
   Scene 2 ‚Üí audio_scene2.wav (duration: 7.8s)
   Scene 3 ‚Üí audio_scene3.wav (duration: 4.1s)

3. SubtitleGenerator
   audio_scene1.wav + Scene 1.text ‚Üí subtitles_scene1.srt
   audio_scene2.wav + Scene 2.text ‚Üí subtitles_scene2.srt
   audio_scene3.wav + Scene 3.text ‚Üí subtitles_scene3.srt

4. VisualSelector
   Scene 1 ‚Üí assets/images/bg_001.jpg
   Scene 2 ‚Üí assets/images/bg_045.jpg
   Scene 3 ‚Üí assets/images/bg_012.jpg

5. MusicSelector
   total_duration: 17.1s ‚Üí assets/music/ambient_03.mp3 (adjusted)

6. VideoAssembler
   [clips] + [transitions] + [music] ‚Üí output/final_video.mp4
```

---

## üõ°Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ —É—Ä–æ–≤–Ω—è–º

**–£—Ä–æ–≤–µ–Ω—å –º–æ–¥—É–ª—è:**
```python
class TTSGenerator:
    def generate(self, scene: Scene):
        try:
            return self._generate_internal(scene)
        except OutOfMemoryError:
            # Fallback: —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏
            return self._generate_in_chunks(scene)
        except ModelLoadError:
            # Fallback: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–ø–∞—Å–Ω—É—é –º–æ–¥–µ–ª—å
            self.load_backup_model()
            return self._generate_internal(scene)
```

**–£—Ä–æ–≤–µ–Ω—å –ø–∞–π–ø–ª–∞–π–Ω–∞:**
```python
class Pipeline:
    def run(self, input_file, output_file):
        try:
            scenes = self.scene_parser.parse(input_file)
            # ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ —à–∞–≥–∏
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {e}")
            raise
```

---

## üê≥ Docker –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### Dockerfile
```dockerfile
FROM python:3.11-slim

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ FFmpeg
RUN apt-get update && apt-get install -y ffmpeg && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
COPY . .

# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
RUN mkdir -p output temp logs

# –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π TTS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
RUN python -c "from TTS.api import TTS; TTS('tts_models/ru/ruslan/fairseq_vits')"

CMD ["python", "main.py", "--help"]
```

### docker-compose.yml
```yaml
version: '3.8'

services:
  text2video:
    build: .
    volumes:
      - ./input:/app/input
      - ./output:/app/output
      - ./assets:/app/assets
      - ./config.yaml:/app/config.yaml
    environment:
      - LOG_LEVEL=INFO
    command: python main.py -i /app/input/script.txt -o /app/output/video.mp4
```

---

## üåç –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —è–∑—ã–∫–æ–≤ –≤ config.yaml

```yaml
tts:
  language: "ru"  # ru | en
  models:
    ru: "tts_models/ru/ruslan/fairseq_vits"
    en: "tts_models/en/ljspeech/tacotron2-DDC"
  
subtitles:
  language: "ru"  # –Ø–∑—ã–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (–∞–≤—Ç–æ –∏–∑ tts.language)
```

### –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —è–∑—ã–∫–∞
```python
class TTSGenerator:
    def __init__(self, config):
        self.language = config['tts']['language']
        model_path = config['tts']['models'][self.language]
        self.tts = TTS(model_path)
```
